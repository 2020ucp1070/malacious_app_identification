{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7b2aa16-9f9a-45d6-9238-8efd4ae19740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 266 ms\n",
      "Wall time: 1.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c7017ba-4181-44c7-b161-28e15050b061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_sampled: (62555, 79)\n",
      "Shape of X_test_sampled: (15639, 79)\n",
      "Shape of y_train_sampled: (62555,)\n",
      "Shape of y_test_sampled: (15639,)\n",
      "CPU times: total: 547 ms\n",
      "Wall time: 682 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load the dataset\n",
    "file_path = 'dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "sampled_df = df.sample(frac=1, random_state=42)\n",
    "\n",
    "# Separate features and target column from the sampled data\n",
    "X_sampled = sampled_df.drop(columns=['calss'])\n",
    "y_sampled = sampled_df['calss']\n",
    "\n",
    "# Perform train-test split (80:20 ratio) on the sampled data\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "    X_sampled, y_sampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shape of the sampled and split data\n",
    "print(f\"Shape of X_train_sampled: {X_train.shape}\")\n",
    "print(f\"Shape of X_test_sampled: {X_test.shape}\")\n",
    "print(f\"Shape of y_train_sampled: {y_train.shape}\")\n",
    "print(f\"Shape of y_test_sampled: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b26013aa-181c-4db2-8dea-ff8d5ec16db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 204 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import  RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.kernel_approximation import RBFSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7206b60d-a926-4037-92c8-81c6ffb581b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 78.1 ms\n",
      "Wall time: 155 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e423c805-f479-47b9-a794-cc19f976828e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_estimators_values = [5,10, 15]\n",
    "random_state_values = [42, 61, 91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3841e35d-da41-4f35-aad0-686632f7c597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models = {\n",
    "    'MLP': MLPClassifier(max_iter=1000, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f7340ad-8795-4c74-8520-16a58a9cfb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done model : MLPClassifier(max_iter=1000, random_state=42),n_estimators: 5,random_state : 42, accuracy : 0.8045271436792634\n",
      "Done model : MLPClassifier(max_iter=1000, random_state=42),n_estimators: 5,random_state : 61, accuracy : 0.8058699405332822\n",
      "Done model : MLPClassifier(max_iter=1000, random_state=42),n_estimators: 5,random_state : 91, accuracy : 0.8032482895325788\n",
      "Done model : MLPClassifier(max_iter=1000, random_state=42),n_estimators: 10,random_state : 42, accuracy : 0.8070209092652983\n",
      "Done model : MLPClassifier(max_iter=1000, random_state=42),n_estimators: 10,random_state : 61, accuracy : 0.8067011957286272\n",
      "Done model : MLPClassifier(max_iter=1000, random_state=42),n_estimators: 10,random_state : 91, accuracy : 0.806637253021293\n",
      "Done model : MLPClassifier(max_iter=1000, random_state=42),n_estimators: 15,random_state : 42, accuracy : 0.8086834196559882\n",
      "Done model : MLPClassifier(max_iter=1000, random_state=42),n_estimators: 15,random_state : 61, accuracy : 0.8091310186073278\n",
      "Done model : MLPClassifier(max_iter=1000, random_state=42),n_estimators: 15,random_state : 91, accuracy : 0.8080439925826459\n",
      "CPU times: total: 4h 33min 38s\n",
      "Wall time: 53min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_models = {}\n",
    "best_hyperparameters = {}\n",
    "best_metrix = {}\n",
    "\n",
    "# Iterate over each model type\n",
    "for model_name, model in models.items():\n",
    "    best_accuracy = 0.0\n",
    "    best_model = None\n",
    "    best_hyperparameter = {}\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    best_f1_score = 0.0\n",
    "\n",
    "    # Iterate over hyperparameter values\n",
    "    for n_estimators in n_estimators_values:\n",
    "        for random_state in random_state_values:\n",
    "            # Initialize Bagging Classifier with current hyperparameters\n",
    "            bagging_model = BaggingClassifier(estimator=model, n_estimators=n_estimators, random_state=random_state)\n",
    "\n",
    "            # Fit model and make predictions\n",
    "            bagging_model.fit(X_train_scaled, y_train)\n",
    "            y_pred = bagging_model.predict(X_test_scaled)\n",
    "\n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, average='weighted',zero_division=0.0)\n",
    "            recall = recall_score(y_test, y_pred, average='weighted',zero_division=0.0)\n",
    "            f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "            \n",
    "            # Update best model if accuracy improves\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_model = bagging_model\n",
    "                best_hyperparameter = {'n_estimators': n_estimators, 'random_state': random_state}\n",
    "                best_precision = precision\n",
    "                best_recall = recall\n",
    "                best_f1_score = f1\n",
    "            print(f\"Done model : {model},n_estimators: {n_estimators},random_state : {random_state}, accuracy : {accuracy}\")\n",
    "\n",
    "    # Store best model, hyperparameters, and metrices for current classifier type\n",
    "    best_models[model_name] = best_model\n",
    "    best_hyperparameters[model_name] = best_hyperparameter\n",
    "    best_metrix[model_name] = {'Accuracy': best_accuracy, 'Precision': best_precision, 'Recall': best_recall, 'F1-score': best_f1_score}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "792a394e-20c3-4efb-a379-7c12d05ef0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MLP Model:\n",
      "Hyperparameters: {'n_estimators': 15, 'random_state': 61}\n",
      "Accuracy: 0.8091310186073278\n",
      "Precision: 0.8101232459288811\n",
      "Recall: 0.8091310186073278\n",
      "F1-score: 0.8078110578627358\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Print best models, hyperparameters, and metrices\n",
    "for model_name, metrics in best_metrix.items():\n",
    "    print(f\"Best {model_name} Model:\")\n",
    "    print(f\"Hyperparameters: {best_hyperparameters[model_name]}\")\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f\"{metric_name}: {value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdc8fe2f-7791-4e2e-a3a1-ef38a72bea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'mlp.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c172bba-7507-44d1-9f13-e3c03ed489b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
