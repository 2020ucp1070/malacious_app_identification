{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7b2aa16-9f9a-45d6-9238-8efd4ae19740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.62 s\n",
      "Wall time: 22.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c7017ba-4181-44c7-b161-28e15050b061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_sampled: (62555, 79)\n",
      "Shape of X_test_sampled: (15639, 79)\n",
      "Shape of y_train_sampled: (62555,)\n",
      "Shape of y_test_sampled: (15639,)\n",
      "CPU times: total: 1.27 s\n",
      "Wall time: 2.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load the dataset\n",
    "file_path = 'dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "sampled_df = df.sample(frac=1, random_state=42)\n",
    "\n",
    "# Separate features and target column from the sampled data\n",
    "X_sampled = sampled_df.drop(columns=['calss'])\n",
    "y_sampled = sampled_df['calss']\n",
    "\n",
    "# Perform train-test split (80:20 ratio) on the sampled data\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "    X_sampled, y_sampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shape of the sampled and split data\n",
    "print(f\"Shape of X_train_sampled: {X_train.shape}\")\n",
    "print(f\"Shape of X_test_sampled: {X_test.shape}\")\n",
    "print(f\"Shape of y_train_sampled: {y_train.shape}\")\n",
    "print(f\"Shape of y_test_sampled: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b26013aa-181c-4db2-8dea-ff8d5ec16db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 234 ms\n",
      "Wall time: 1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import  RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.kernel_approximation import RBFSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7206b60d-a926-4037-92c8-81c6ffb581b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 234 ms\n",
      "Wall time: 393 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e423c805-f479-47b9-a794-cc19f976828e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_estimators_values = [10, 15, 20]\n",
    "random_state_values = [42, 61, 91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3841e35d-da41-4f35-aad0-686632f7c597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models = {\n",
    "    'AdaBoost': AdaBoostClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f7340ad-8795-4c74-8520-16a58a9cfb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done model : AdaBoostClassifier(),n_estimators: 10,random_state : 42, accuracy : 0.7143039836306669\n",
      "Done model : AdaBoostClassifier(),n_estimators: 10,random_state : 61, accuracy : 0.7143679263380012\n",
      "Done model : AdaBoostClassifier(),n_estimators: 10,random_state : 91, accuracy : 0.7174371762900441\n",
      "Done model : AdaBoostClassifier(),n_estimators: 15,random_state : 42, accuracy : 0.7176290044120468\n",
      "Done model : AdaBoostClassifier(),n_estimators: 15,random_state : 61, accuracy : 0.7141760982159985\n",
      "Done model : AdaBoostClassifier(),n_estimators: 15,random_state : 91, accuracy : 0.7174371762900441\n",
      "Done model : AdaBoostClassifier(),n_estimators: 20,random_state : 42, accuracy : 0.7212097960227636\n",
      "Done model : AdaBoostClassifier(),n_estimators: 20,random_state : 61, accuracy : 0.7107871347272844\n",
      "Done model : AdaBoostClassifier(),n_estimators: 20,random_state : 91, accuracy : 0.7183323741927233\n",
      "CPU times: total: 29min 48s\n",
      "Wall time: 42min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_models = {}\n",
    "best_hyperparameters = {}\n",
    "best_metrix = {}\n",
    "\n",
    "# Iterate over each model type\n",
    "for model_name, model in models.items():\n",
    "    best_accuracy = 0.0\n",
    "    best_model = None\n",
    "    best_hyperparameter = {}\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "    best_f1_score = 0.0\n",
    "\n",
    "    # Iterate over hyperparameter values\n",
    "    for n_estimators in n_estimators_values:\n",
    "        for random_state in random_state_values:\n",
    "            # Initialize Bagging Classifier with current hyperparameters\n",
    "            bagging_model = BaggingClassifier(estimator=model, n_estimators=n_estimators, random_state=random_state)\n",
    "\n",
    "            # Fit model and make predictions\n",
    "            bagging_model.fit(X_train_scaled, y_train)\n",
    "            y_pred = bagging_model.predict(X_test_scaled)\n",
    "\n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, average='weighted',zero_division=0.0)\n",
    "            recall = recall_score(y_test, y_pred, average='weighted',zero_division=0.0)\n",
    "            f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "            \n",
    "            # Update best model if accuracy improves\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_model = bagging_model\n",
    "                best_hyperparameter = {'n_estimators': n_estimators, 'random_state': random_state}\n",
    "                best_precision = precision\n",
    "                best_recall = recall\n",
    "                best_f1_score = f1\n",
    "            print(f\"Done model : {model},n_estimators: {n_estimators},random_state : {random_state}, accuracy : {accuracy}\")\n",
    "\n",
    "    # Store best model, hyperparameters, and metrices for current classifier type\n",
    "    best_models[model_name] = best_model\n",
    "    best_hyperparameters[model_name] = best_hyperparameter\n",
    "    best_metrix[model_name] = {'Accuracy': best_accuracy, 'Precision': best_precision, 'Recall': best_recall, 'F1-score': best_f1_score}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "792a394e-20c3-4efb-a379-7c12d05ef0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AdaBoost Model:\n",
      "Hyperparameters: {'n_estimators': 20, 'random_state': 42}\n",
      "Accuracy: 0.7212097960227636\n",
      "Precision: 0.7257498497622339\n",
      "Recall: 0.7212097960227636\n",
      "F1-score: 0.7113769985964435\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Print best models, hyperparameters, and metrices\n",
    "for model_name, metrics in best_metrix.items():\n",
    "    print(f\"Best {model_name} Model:\")\n",
    "    print(f\"Hyperparameters: {best_hyperparameters[model_name]}\")\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f\"{metric_name}: {value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4a9169b-d732-4b3e-b019-8f9b41b3d758",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'ada_boost.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d82f091-1d22-42d0-a39f-975fa3c706b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
